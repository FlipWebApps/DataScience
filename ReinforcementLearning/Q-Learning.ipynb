{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Example\n",
    "\n",
    "Reusable Q-Learning class with Cliff walking example\n",
    "\n",
    "References:\n",
    "* https://oneraynyday.github.io/ml/2018/09/30/Reinforcement-Learning-TD/\n",
    "* https://github.com/OneRaynyDay/RLEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General purpose finite model baseclass that requires some functions to be implemented.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from copy import deepcopy\n",
    "\n",
    "class FiniteModel(object, metaclass=ABCMeta):\n",
    "    def __init__(self, state_space, action_space, gamma=1.0, epsilon=0.1):\n",
    "        \"\"\"FiniteModel takes in state_space and action_space (finite) \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        state_space: int OR list[observation], where observation is any hashable type from env's obs.\n",
    "        action_space: int OR list[action], where action is any hashable type from env's actions.\n",
    "        gamma: float, discounting factor.\n",
    "        epsilon: float, epsilon-greedy parameter.\n",
    "        \n",
    "        If the parameter is an int, then we generate a list, and otherwise we generate a dictionary.\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = None\n",
    "        if isinstance(action_space, int):\n",
    "            self.action_space = np.arange(action_space)\n",
    "            actions = [0]*action_space\n",
    "            # Action representation\n",
    "            self._act_rep = \"list\"\n",
    "        else:\n",
    "            self.action_space = action_space\n",
    "            actions = {k:0 for k in action_space}\n",
    "            self._act_rep = \"dict\"\n",
    "        if isinstance(state_space, int):\n",
    "            self.state_space = np.arange(state_space)\n",
    "            self.Q = [deepcopy(actions) for _ in range(state_space)]\n",
    "        else:\n",
    "            self.state_space = state_space\n",
    "            self.Q = {k:deepcopy(actions) for k in state_space}\n",
    "            \n",
    "        # Frequency of state/action.\n",
    "        self.Ql = deepcopy(self.Q)\n",
    "\n",
    "       \n",
    "    def pi(self, action, state):\n",
    "        \"\"\"pi(a,s,A,V) := pi(a|s)\n",
    "        We take the argmax_a of Q(s,a).\n",
    "        q[s] = [q(s,0), q(s,1), ...]\n",
    "        \"\"\"\n",
    "        if self._act_rep == \"list\":\n",
    "            if action == np.argmax(self.Q[state]):\n",
    "                return 1\n",
    "            return 0\n",
    "        elif self._act_rep == \"dict\":\n",
    "            if action == max(self.Q[state], key=self.Q[state].get):\n",
    "                return 1\n",
    "            return 0\n",
    "    \n",
    "   \n",
    "    def b(self, action, state):\n",
    "        \"\"\"b(a,s,A) := b(a|s) \n",
    "        Sometimes you can only use a subset of the action space\n",
    "        given the state.\n",
    "        Randomly selects an action from a uniform distribution.\n",
    "        \"\"\"\n",
    "        return self.epsilon/len(self.action_space) + (1-self.epsilon) * self.pi(action, state)\n",
    "\n",
    "\n",
    "    def choose_action(self, policy, state):\n",
    "        \"\"\"Uses specified policy to select an action randomly given the state.\n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        policy: function, can be self.pi, or self.b, or another custom policy.\n",
    "        state: observation of the environment.\n",
    "        \"\"\"\n",
    "        probs = [policy(a, state) for a in self.action_space]\n",
    "        return np.random.choice(self.action_space, p=probs)\n",
    "\n",
    "   \n",
    "    @abstractmethod\n",
    "    def score(self, env, policy, n_samples=1000):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_Q(self, sequence):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General purpose Q-Learning model for training off-policy methods.\n",
    "\"\"\"\n",
    "class FiniteQLearningModel(FiniteModel):\n",
    "    def __init__(self, state_space, action_space, gamma=1.0, epsilon=0.1, alpha=0.01):\n",
    "        \"\"\"FiniteQLearningModel takes in state_space and action_space (finite) \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        state_space: int OR list[observation], where observation is any hashable type from env's obs.\n",
    "        action_space: int OR list[action], where action is any hashable type from env's actions.\n",
    "        gamma: float, discounting factor.\n",
    "        epsilon: float, epsilon-greedy parameter.\n",
    "        \n",
    "        If the parameter is an int, then we generate a list, and otherwise we generate a dictionary.\n",
    "        >>> m = FiniteQLearningModel(2,3,epsilon=0)\n",
    "        >>> m.Q\n",
    "        [[0, 0, 0], [0, 0, 0]]\n",
    "        >>> m.Q[0][1] = 1\n",
    "        >>> m.Q\n",
    "        [[0, 1, 0], [0, 0, 0]]\n",
    "        >>> m.pi(1, 0)\n",
    "        1\n",
    "        >>> m.pi(1, 1)\n",
    "        0\n",
    "        \"\"\"\n",
    "        super(FiniteQLearningModel, self).__init__(state_space, action_space, gamma, epsilon) \n",
    "        self.alpha = alpha\n",
    "       \n",
    "\n",
    "    def update_Q(self, sars):\n",
    "        \"\"\"Performs a TD(0) action-value update using a single step.\n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        sars: (state, action, reward, state, action) or (state, action, reward, state), \n",
    "            an event in an episode.\n",
    "        \n",
    "        NOTE: For Q-Learning, we don't actually use the next action, since we argmax.\n",
    "        \"\"\"\n",
    "        # Generate returns, return ratio\n",
    "        if len(sars) > 4:\n",
    "            sars = sars[:4]\n",
    "\n",
    "        p_state, p_action, reward, n_state = sars\n",
    "        q = self.Q[p_state][p_action]\n",
    "        max_q = max(self.Q[n_state].values()) if isinstance(self.Q[n_state], dict) else max(self.Q[n_state])\n",
    "        self.Q[p_state][p_action] = q + self.alpha * \\\n",
    "            (reward + self.gamma * max_q - q)\n",
    "   \n",
    "\n",
    "    def score(self, env, policy, n_samples=1000):\n",
    "        \"\"\"Evaluates a specific policy with regards to the env.\n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        env: an openai gym env, or anything that follows the api.\n",
    "        policy: a function, could be self.pi, self.b, etc.\n",
    "        \"\"\"\n",
    "        rewards = []\n",
    "        for _ in range(n_samples):\n",
    "            observation = env.reset()\n",
    "            cum_rewards = 0\n",
    "            while True:\n",
    "                action = self.choose_action(policy, observation)\n",
    "                observation, reward, done, _ = env.step(action)\n",
    "                cum_rewards += reward\n",
    "                if done:\n",
    "                    rewards.append(cum_rewards)\n",
    "                    break\n",
    "        return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Cliff Walking\n",
    "The change to the code is actually very small because, as I said, Monte Carlo sampling is pretty environment agnostic.\n",
    "\n",
    "The cliff walking problem is a map where some blocks are cliffs and others are platforms. You get -1 reward for every step on a platform, and -100 reward for every time you fall down the cliff. When you land on a cliff, you go back to the beginning. For how big the map is, -17.0 per episode is a near-optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: If you try to set eps to a very low value,\n",
    "# And you attempt to get the m.score() of m.pi, there may not\n",
    "# be guarranteed convergence.\n",
    "eps = 3000\n",
    "S = 4*12\n",
    "A = 4\n",
    "START_EPS = 0.7\n",
    "m = FiniteQLearningModel(S, A, epsilon=START_EPS)\n",
    "\n",
    "SAVE_FIG = False\n",
    "history = []\n",
    "\n",
    "for i in range(1, eps+1):\n",
    "    ep = []\n",
    "    prev_observation = env.reset()\n",
    "    prev_action = m.choose_action(m.b, prev_observation)\n",
    "\n",
    "    total_reward = 0\n",
    "    while True:        \n",
    "        # Run simulation\n",
    "        next_observation, reward, done, _ = env.step(prev_action)\n",
    "        next_action = m.choose_action(m.b, next_observation)\n",
    "\n",
    "        m.update_Q((prev_observation, prev_action, reward, next_observation, next_action))\n",
    "\n",
    "        prev_observation = next_observation\n",
    "        prev_action = next_action\n",
    "\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    history.append(total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final expected returns : -13.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Final expected returns : {}\".format(m.score(env, m.pi, n_samples=10)))\n",
    "                              \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "X = 12\n",
    "Y = 4\n",
    "Fx = np.zeros((Y, X))\n",
    "Fy = np.zeros((Y, X))\n",
    "for y in range(Y):\n",
    "    for x in range(X):\n",
    "        amax = np.argmax(m.Q[x+y*12])\n",
    "        if amax == 0: # UP\n",
    "            Fy[y, x] = -1\n",
    "        elif amax == 1: # RIGHT\n",
    "            Fx[y, x] = 1\n",
    "        elif amax == 2: # DOWN\n",
    "            Fy[y, x] = 1\n",
    "        elif amax == 3: # LEFT\n",
    "            Fx[y, x] = -1\n",
    "plt.quiver(Fx,Fy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another observation we can see is that Q-learning’s average reward is bad. This is due to the fact that Q-learning tries to take the optimal action, but gets screwed over by the ϵ probability of falling off a cliff due to the stochasticity of the ϵ-greedy policy that it uses to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
